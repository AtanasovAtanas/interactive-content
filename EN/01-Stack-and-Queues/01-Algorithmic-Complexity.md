[slide]
# Algorithmic Complexity

**Algorithm complexity** is a **measure** which evaluates the order of the **count of operations**, performed by a given algorithm as a function of the size of the input data.

In other words, **complexity** is a rough **approximation of the number of steps** necessary to execute an algorithm.

When we evaluate complexity we speak of **order of operation count**, not of their exact count.

Algorithm complexity is commonly represented with the **O(f) notation**, also known as **asymptotic notation** or **"Big O notation"**, where **f** is the function of the size of the input data.

The asymptotic computational complexity **O(f)** measures the order of the consumed resources (CPU time, memory, etc.) by certain algorithm expressed as function of the input data size.

Complexity can be **constant**, **logarithmic**, **linear**, **n*log(n)**, **quadratic**, **cubic**, **exponential**, etc.

This is respectively the order of constant, logarithmic, linear and so on, number of steps, are executed to solve a given problem.

For simplicity, sometime instead of **"algorithms complexity"** or just **"complexity"** we use the term **"running time"**.


[/slide]