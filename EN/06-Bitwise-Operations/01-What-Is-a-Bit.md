[slide]
# What is a Bit?

The bits (zero or one) and their fundamental importance in computer science

The **units of measuring** data (bit, byte, kilobyte, megabyte, gigabyte and so on) and their role in computing and in the digital world.

Bits: these very small portions of data (ones and zeroes), used to represent numbers, text and anything else in the digital world.

Bits are the smallest units of data used in computing.

A **bit** is a single unit of data, which takes only two possible values: either `0` or `1`.

One bit can store anything, which has two separate states:
Logical values (true of false), for example "is the registration open now" or it's is closed.

Algebraic signs (plus or minus), for example positive number or negative number.

Activation states (on or off), for example "the lights are switched on" or "the lights are switched off".

In the computer memory bits don't stay alone. They are organized in sequences of 8 bits, called bytes (or sometimes octets). These are the machine "words". 
Some machines use 8-bit words, others use 16-bit words, while others use 32-bit words, but usually bits in memory are accessed in groups (bytes in most systems). 
This is the reason why the capacity of computer memory is measured in bytes and megabytes (not in bits and megabits).


[/slide]